{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for NaN values in features and target:\n",
      "Year                          0\n",
      "Seq                           0\n",
      "Glide                         0\n",
      "Disaster Group                0\n",
      "Disaster Subgroup             0\n",
      "Disaster Subtype              0\n",
      "Disaster Subsubtype           0\n",
      "Event Name                    0\n",
      "Country                       0\n",
      "ISO                           0\n",
      "Region                        0\n",
      "Continent                     0\n",
      "Location                      0\n",
      "Origin                        0\n",
      "Associated Dis                0\n",
      "Associated Dis2               0\n",
      "OFDA Response                 0\n",
      "Appeal                        0\n",
      "Declaration                   0\n",
      "Aid Contribution              0\n",
      "Dis Mag Value                 0\n",
      "Dis Mag Scale                 0\n",
      "Latitude                      0\n",
      "Longitude                     0\n",
      "Local Time                    0\n",
      "River Basin                   0\n",
      "Start Year                    0\n",
      "Start Month                   0\n",
      "Start Day                     0\n",
      "End Year                      0\n",
      "End Month                     0\n",
      "End Day                       0\n",
      "Total Deaths                  0\n",
      "No Injured                    0\n",
      "No Affected                   0\n",
      "No Homeless                   0\n",
      "Total Affected                0\n",
      "Insured Damages ('000 US$)    0\n",
      "Total Damages ('000 US$)      0\n",
      "CPI                           0\n",
      "Adm Level                     0\n",
      "Admin1 Code                   0\n",
      "Admin2 Code                   0\n",
      "Geo Locations                 0\n",
      "dtype: int64\n",
      "0\n",
      "Training RandomForest model...\n",
      "Accuracy with RandomForest: 99.38%\n",
      "Classification Report for RandomForest:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "             Drought       0.99      1.00      1.00       154\n",
      "          Earthquake       1.00      1.00      1.00       309\n",
      "            Epidemic       0.99      1.00      1.00       300\n",
      "Extreme temperature        1.00      0.98      0.99       121\n",
      "               Flood       1.00      1.00      1.00      1111\n",
      "  Insect infestation       1.00      0.89      0.94        19\n",
      "           Landslide       0.95      0.98      0.97       155\n",
      " Mass movement (dry)       0.00      0.00      0.00        10\n",
      "               Storm       1.00      1.00      1.00       899\n",
      "   Volcanic activity       0.98      1.00      0.99        53\n",
      "            Wildfire       1.00      0.98      0.99        94\n",
      "\n",
      "            accuracy                           0.99      3225\n",
      "           macro avg       0.90      0.89      0.90      3225\n",
      "        weighted avg       0.99      0.99      0.99      3225\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('sam.csv')\n",
    "\n",
    "# Drop rows with missing target values\n",
    "data = data.dropna(subset=['Disaster Type'])\n",
    "\n",
    "# Drop classes with very few instances\n",
    "class_counts = data['Disaster Type'].value_counts()\n",
    "data = data[data['Disaster Type'].isin(class_counts[class_counts >= 5].index)]\n",
    "\n",
    "# Define features and target\n",
    "X = data.drop(columns=['Disaster Type'])\n",
    "y = data['Disaster Type']\n",
    "\n",
    "# Handle missing values in features\n",
    "X = X.replace('', pd.NA).fillna('')  # Replace empty strings with NaN and then fill with empty string for text columns\n",
    "\n",
    "# Check for NaN values\n",
    "print(\"Checking for NaN values in features and target:\")\n",
    "print(X.isnull().sum())\n",
    "print(y.isnull().sum())\n",
    "\n",
    "# Split the data into training and testing sets with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Process text columns\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=3000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train['Event Name'].astype(str) + \" \" + X_train['Location'].astype(str))\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test['Event Name'].astype(str) + \" \" + X_test['Location'].astype(str))\n",
    "\n",
    "# Convert TF-IDF output to DataFrame and ensure numeric columns are properly handled\n",
    "X_train_tfidf_df = pd.DataFrame(X_train_tfidf.toarray(), index=X_train.index)\n",
    "X_test_tfidf_df = pd.DataFrame(X_test_tfidf.toarray(), index=X_test.index)\n",
    "\n",
    "# Drop text columns before combining\n",
    "X_train_numeric = X_train.drop(columns=['Event Name', 'Location'])\n",
    "X_test_numeric = X_test.drop(columns=['Event Name', 'Location'])\n",
    "\n",
    "# Identify columns with non-numeric data\n",
    "non_numeric_cols = X_train_numeric.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Convert all non-numeric columns to strings\n",
    "X_train_numeric[non_numeric_cols] = X_train_numeric[non_numeric_cols].astype(str)\n",
    "X_test_numeric[non_numeric_cols] = X_test_numeric[non_numeric_cols].astype(str)\n",
    "\n",
    "# Apply OneHotEncoder to the non-numeric columns\n",
    "onehot_encoder = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), non_numeric_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "X_train_encoded = onehot_encoder.fit_transform(X_train_numeric)\n",
    "X_test_encoded = onehot_encoder.transform(X_test_numeric)\n",
    "\n",
    "# Combine TF-IDF features with the encoded numeric features\n",
    "X_train_combined = pd.concat([X_train_tfidf_df, pd.DataFrame(X_train_encoded.toarray(), index=X_train.index)], axis=1)\n",
    "X_test_combined = pd.concat([X_test_tfidf_df, pd.DataFrame(X_test_encoded.toarray(), index=X_test.index)], axis=1)\n",
    "\n",
    "# Initialize and train the model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "print(\"Training RandomForest model...\")\n",
    "try:\n",
    "    model.fit(X_train_combined, y_train)\n",
    "    y_pred = model.predict(X_test_combined)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy with RandomForest: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Classification Report for RandomForest:\\n{classification_report(y_test, y_pred)}\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"Error training RandomForest: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_saved' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Print the saved accuracy\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy with RandomForest: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy_saved\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy_saved' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
